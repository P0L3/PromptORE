{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from promptore_utils_n import *\n",
    "\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    device = 'cuda'\n",
    "else:\n",
    "    device = 'cpu'\n",
    "\n",
    "print(device)\n",
    "    # Simulating argparse in a notebook environment\n",
    "class Args:\n",
    "    def __init__(self):\n",
    "        self.seed = 0  # Random seed\n",
    "        self.n_rel = 160  # Number of relations/clusters\n",
    "        self.max_len = 300  # Maximum length of tokens\n",
    "        self.auto_n_rel = False  # Set to True if you want to estimate the number of clusters\n",
    "        self.min_n_rel = 777  # Minimum number of relations to estimate (if auto_n_rel=True)\n",
    "        self.max_n_rel = 1000  # Maximum number of relations to estimate (if auto_n_rel=True)\n",
    "        self.step_n_rel = 5  # Step size for relation estimation (if auto_n_rel=True)\n",
    "        self.files = []  # Files to load from Fewrel (leave empty for now)\n",
    "        self.data = \"ls\"\n",
    "\n",
    "args = Args()\n",
    "\n",
    "# Read wikiphi3 files\n",
    "df_dataset = parse_wikiphi3_with_dynamic_markers(\"DATA/wikiphi3_data_49410.pickle\", \"[E1] \", \" [/E1]\", \"[E2] \", \" [/E2]\", \"[MASK]\")\n",
    "# parse_labelstudio_with_dynamic_markers(\"DATA/project-6-at-2025-04-22-13-14-67864b63.json\", \"[E1] \", \" [/E1]\", \"[E2] \", \" [/E2]\", \"[MASK]\") # parse_wikiphi3(\"DATA/wikiphi3_data_49410.pickle\")\n",
    "# parse_labelstudio(\"DATA/project-6-at-2025-04-22-13-14-67864b63.json\")\n",
    "\n",
    "# Compute relation embeddings\n",
    "print(\"Compute relation embeddings\")\n",
    "relation_embeddings = compute_promptore_relation_embedding(\n",
    "    df_dataset, \n",
    "    template=\"{sent}\", \n",
    "    max_len=args.max_len, \n",
    "    device=device, \n",
    "    emb=4, \n",
    "    data=\"wikiphi3\")\n",
    "\n",
    "# Compute clustering\n",
    "print(\"Compute clustering\")\n",
    "if args.auto_n_rel:\n",
    "    n_rel = estimate_n_rel(\n",
    "        relation_embeddings, args.seed, (args.min_n_rel, args.max_n_rel), args.step_n_rel)\n",
    "    print(f'Estimated n_rel={n_rel}')\n",
    "else:\n",
    "    n_rel = args.n_rel\n",
    "\n",
    "print(\"Predict labels\")\n",
    "predicted_labels = compute_kmeans_clustering(relation_embeddings, n_rel, args.seed)\n",
    "\n",
    "# Evaluation\n",
    "b3, b3_prec, b3_rec, v, v_hom, v_comp, ari = evaluate_promptore(relation_embeddings, \n",
    "                                                                predicted_labels)\n",
    "print(f'B3: prec={b3_prec} rec={b3_rec} f1={b3}')\n",
    "print(f'V-measure: hom={v_hom} comp={v_comp} f1={v}')\n",
    "print(f'ARI={ari}')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(predicted_labels)\n",
    "relation_embeddings[\"predicted_labels\"] = predicted_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "relation_embeddings[relation_embeddings[\"predicted_labels\"] == 34].sort_values(by=\"output_r\")[[\"sentence\", \"head\", \"output_r\", \"tail\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visuals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "summary = relation_embeddings.groupby('predicted_labels').agg(\n",
    "    total_instances=('output_r', 'count'),\n",
    "    unique_output_r=('output_r', pd.Series.nunique)\n",
    ").reset_index()\n",
    "\n",
    "\n",
    "\n",
    "# Apply Min-Max scaling to 'total_instances'\n",
    "scaler = MinMaxScaler()\n",
    "summary['total_instances_scaled'] = scaler.fit_transform(summary[['total_instances']])\n",
    "\n",
    "print(summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "# Bar chart comparing total instances vs unique output_r values\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.barplot(data=summary.melt(id_vars='predicted_labels'), x='predicted_labels', y='value', hue='variable')\n",
    "plt.title('Cluster-wise: Total Instances and Unique output_r Values')\n",
    "plt.xlabel('Predicted Label (Cluster)')\n",
    "plt.ylabel('Count')\n",
    "plt.xticks(rotation=0)\n",
    "plt.legend(title='')\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary['diversity_ratio'] = (summary['unique_output_r'] / summary['total_instances']) / summary[\"total_instances_scaled\"]\n",
    "\n",
    "summary.sort_values(by='diversity_ratio', ascending=True, inplace=True)\n",
    "plt.figure(figsize=(16, 10))\n",
    "sns.barplot(data=summary, x='predicted_labels', y='diversity_ratio', width=0.5, palette='viridis', order=summary.sort_values(by='diversity_ratio', ascending=False).predicted_labels)\n",
    "plt.title('Diversity Ratio per Cluster (Unique output_r / Total Instances)')\n",
    "plt.xlabel('Predicted Label (Cluster)')\n",
    "plt.ylabel('Diversity Ratio')\n",
    "plt.xticks(rotation = 90)\n",
    "plt.ylim(0, 1.05)\n",
    "plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dataset.iloc[1397]\n",
    "\n",
    "print(df_dataset.iloc[1397][\"sent\"])\n",
    "print(df_dataset.iloc[1397][\"r\"])\n",
    "print(len(df_dataset.iloc[1397][\"sent\"]))\n",
    "\n",
    "for _, a in df_dataset.sample(20).iterrows():\n",
    "    print(len(a[\"sent\"]))\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "promptore",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
